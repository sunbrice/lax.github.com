---
layout: post
title: "Nginx访问计数和频率控制"
date: 2015-06-23 11:49:51 +0800
comments: true
categories: [Technology]
tags: [Nginx, Redis, Lua]
---

### 访问频率控制的需求现状

在使用了负载均衡设施的网站中，对 HTTP 请求做访问控制（频率控制）是个经常遇到的需求。
频率控制的主要目的，传统应用场景中要___保护后端系统___。
在多租户的云服务上，通过频率控制__对不同租户的资源使用量做有效分配__，避免相互影响访问质量。

`Nginx` 比较早的版本即有相关频率控制功能。

常用的有两个模块：

*    [ngx_http_limit_req_module](http://nginx.org/en/docs/http/ngx_http_limit_req_module.html)

针对一个定义的 key，控制`请求处理频率`。(nginx-0.7.21 版本实现)

*    [ngx_http_limit_conn_module](http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html)

针对一个定义的 key，控制`同时连接数`。

这两个模块是按秒或分的时间精度来限制，使用 `10r/s` 或 `1r/m` 这种方式能够比较容易配置。
`Tengine` 改进了频率控制相关功能，但是仍然简单粗暴，支持的策略比较少，难以满足个性化的时间窗口需要。。

另外，以上2个模块针对进程级别做控制，多个 Nginx 部署之间不共享数据。
实际部署中，`Nginx` 作为负载均衡设施，一般会部署多台组成集群。
这时的需求是对这个集群进行保护，不是对单个server的访问限制，所以基于单机的限制有了明显的局限性。

### 频率控制系统的实现目标

设计一个频率控制系统，我们有以下实现目标：

1.  状态数据共享

    从单机限制到集群化整体限制，需要有统一维护状态的存储

2.  简化配置

    数据metrics可定制key，尽量减少（各种判断）逻辑

3.  资源消耗低

    高效的字符串操作

    网络流量低，使用长连接

4.  实时反馈

    可允许边缘情况限制部准确，但是不能有延时。

    这也决定了基于日志分析的方案不能达到。

5.  数据持久化

    历史数据保存，可追溯

6.  失败保护

    作为辅助系统，内部失败时应该能使对外服务正常进行。


根据实际业务需求协商确定出公认的目标，是实现的关键步骤。

### 架构设计

在设计目标指引下，选择使用稳定高效的开源软件来实现。
最终形成了 `Nginx` + `Lua` + `Redis` 的方案。

基于负载均衡层的流控系统，可以串联部署在负载均衡后端，作为应用层的代理，也可以并联部署在负载均衡后端旁路。
我们采用了旁路的方式来部署。

架构图： TODO

 LB
 |
 ----
 NGINX
 Redis
 ----
 |
 APP server
 |  |  |
 Queue Cache DB


#### 组建失败保护：

* Nginx 作为基础服务，有前端 keepalived 提供故障转移
* Lua 作为配置的一部分，上线前经过测试环境的单元测试验证
* Redis 出现宕机导致失败后，可以选择直接跳出控制逻辑，根据实际情况默认返回允许或拒绝。

### 关键配置

#### 1. 使用 `nginx` 的 `map` 功能或 `location regex` 规范化 metric name

#### 2. counter incr操作

#### 3. 多时间维度

#### 4. 保存与读取 limit 上限设置

#### 5. 利用 [Redis Pipelining](http://redis.io/topics/pipelining)
同一次请求会产生多个 redis 操作，没有前后依赖关系，使用 redis 的 batch 方式减少交互

#### 6. 与 Redis 保持长连接

### 效果
#### 功能与性能评估
在客户端使用 `ab` 模拟请求，关注的方面：

* nginx `响应时间`的对比（proxy and static）
* redis `连接数`
* nginx 和 redis 的 `cpu 利用率`
* redis `failover`
* 边缘情况测试

### 思路总结

最终方案各部分采用了成熟的开源方案，有一些综合的优势：

* 需要的代码量比较小
* 在性能和稳定性方面能够满足较长时间的需求
* Redis 容量可以通过 codis 等工具进一步扩展

但是在遇到与业务深度分析的场景时，Nginx 端实现则会有比较大的代价。
比如针对 API 请求中的 JSON 数据做有效性校验，业务逻辑和容错方面的代码量将显著增加。
从开发成本来看这不是一个好的选择，对 Nginx 维护人员的能力也是个挑战。

### 展望

可以进一步优化为使用 redis scripting，也是通过 lua 脚本，将所有逻辑放到 redis 中实现。
既能够达到现有方案使用 [Redis Pipelining] 减少操作延时的效果，还能进一步减少读写操作延时。
